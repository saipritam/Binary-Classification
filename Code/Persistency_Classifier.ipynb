{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Install necessary packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-requisities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#requirements.txt \n",
    "!pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:darkgreen; font-style: italic; font-size: 15px\">Prerequisite Code #1 for <b>suppressing warning</b> is EXECUTED!</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "from IPython.display import HTML, display, Markdown, clear_output\n",
    "import random\n",
    "import logging\n",
    "\n",
    "import os\n",
    "import getpass\n",
    "import platform\n",
    "import json\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "#Setting random seed - 41 in this case\n",
    "random.seed(41)\n",
    "\n",
    "display(Markdown('<span style=\"color:darkgreen; font-style: italic; font-size: 15px\">Prerequisite Code #1 for <b>suppressing warning</b> is EXECUTED!</span>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packges needed for data cleaning and pre-processing ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder          \n",
    "from sklearn.model_selection import train_test_split  \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import copy\n",
    "import IPython\n",
    "import seaborn as sns\n",
    "# import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from termcolor import colored\n",
    "import re\n",
    "import sympy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required for pre-processing and modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import roc_curve\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import VotingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Lars\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import precision_recall_curve, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('Data.xlsx', sheet_name='Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Peek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " <span style=\"color:darkgreen; font-style:italic; font-size:15px\">  <b>First few rows of the dataset is shown below   </b></span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ptid</th>\n",
       "      <th>Persistency_Flag</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Race</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Region</th>\n",
       "      <th>Age</th>\n",
       "      <th>Speciality</th>\n",
       "      <th>Gluco_Prior_Ntm</th>\n",
       "      <th>Gluco_During_Rx</th>\n",
       "      <th>...</th>\n",
       "      <th>Risk_Family_History_Of_Osteoporosis</th>\n",
       "      <th>Risk_Low_Calcium_Intake</th>\n",
       "      <th>Risk_Vitamin_D_Insufficiency</th>\n",
       "      <th>Risk_Poor_Health_Frailty</th>\n",
       "      <th>Risk_Excessive_Thinness</th>\n",
       "      <th>Risk_Hysterectomy_Oophorectomy</th>\n",
       "      <th>Risk_Estrogen_Deficiency</th>\n",
       "      <th>Risk_Immobilization</th>\n",
       "      <th>Risk_Recurring_Falls</th>\n",
       "      <th>Count_Of_Risks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P701</td>\n",
       "      <td>Non-Persistent</td>\n",
       "      <td>Female</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Not Hispanic</td>\n",
       "      <td>South</td>\n",
       "      <td>&gt;75</td>\n",
       "      <td>GENERAL PRACTITIONER</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P702</td>\n",
       "      <td>Non-Persistent</td>\n",
       "      <td>Female</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Not Hispanic</td>\n",
       "      <td>South</td>\n",
       "      <td>55-65</td>\n",
       "      <td>GENERAL PRACTITIONER</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P703</td>\n",
       "      <td>Non-Persistent</td>\n",
       "      <td>Female</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>55-65</td>\n",
       "      <td>GENERAL PRACTITIONER</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P704</td>\n",
       "      <td>Persistent</td>\n",
       "      <td>Female</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Not Hispanic</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>65-75</td>\n",
       "      <td>GENERAL PRACTITIONER</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P705</td>\n",
       "      <td>Persistent</td>\n",
       "      <td>Female</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Not Hispanic</td>\n",
       "      <td>Other/Unknown</td>\n",
       "      <td>55-65</td>\n",
       "      <td>GENERAL PRACTITIONER</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ptid Persistency_Flag  Gender       Race     Ethnicity         Region  \\\n",
       "0  P701   Non-Persistent  Female  Caucasian  Not Hispanic          South   \n",
       "1  P702   Non-Persistent  Female  Caucasian  Not Hispanic          South   \n",
       "2  P703   Non-Persistent  Female  Caucasian      Hispanic        Midwest   \n",
       "3  P704       Persistent  Female  Caucasian  Not Hispanic        Midwest   \n",
       "4  P705       Persistent  Female  Caucasian  Not Hispanic  Other/Unknown   \n",
       "\n",
       "     Age            Speciality Gluco_Prior_Ntm Gluco_During_Rx  ...  \\\n",
       "0    >75  GENERAL PRACTITIONER               N               N  ...   \n",
       "1  55-65  GENERAL PRACTITIONER               N               N  ...   \n",
       "2  55-65  GENERAL PRACTITIONER               N               N  ...   \n",
       "3  65-75  GENERAL PRACTITIONER               N               Y  ...   \n",
       "4  55-65  GENERAL PRACTITIONER               Y               Y  ...   \n",
       "\n",
       "   Risk_Family_History_Of_Osteoporosis Risk_Low_Calcium_Intake  \\\n",
       "0                                    N                       N   \n",
       "1                                    N                       N   \n",
       "2                                    N                       Y   \n",
       "3                                    N                       N   \n",
       "4                                    N                       N   \n",
       "\n",
       "  Risk_Vitamin_D_Insufficiency Risk_Poor_Health_Frailty  \\\n",
       "0                            N                        N   \n",
       "1                            N                        N   \n",
       "2                            N                        N   \n",
       "3                            N                        N   \n",
       "4                            N                        N   \n",
       "\n",
       "  Risk_Excessive_Thinness Risk_Hysterectomy_Oophorectomy  \\\n",
       "0                       N                              N   \n",
       "1                       N                              N   \n",
       "2                       N                              N   \n",
       "3                       N                              N   \n",
       "4                       N                              N   \n",
       "\n",
       "  Risk_Estrogen_Deficiency Risk_Immobilization Risk_Recurring_Falls  \\\n",
       "0                        N                   N                    N   \n",
       "1                        N                   N                    N   \n",
       "2                        N                   N                    N   \n",
       "3                        N                   N                    N   \n",
       "4                        N                   N                    N   \n",
       "\n",
       "  Count_Of_Risks  \n",
       "0              0  \n",
       "1              0  \n",
       "2              2  \n",
       "3              1  \n",
       "4              1  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(Markdown(\"\"\" <span style=\"color:darkgreen; font-style:italic; font-size:15px\">  <b>First few rows of the dataset is shown below   </b></span>\"\"\"))\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[35m\n",
      "Column Names (Before Formatting):\u001b[0m \n",
      "Ptid || Persistency_Flag || Gender || Race || Ethnicity || Region || Age || Speciality || Gluco_Prior_Ntm || Gluco_During_Rx || Dexa_Freq_During_Rx || Dexa_During_Rx || Frag_Frac_Prior_Ntm || Frag_Frac_During_Rx || Risk_Segment_Prior_Ntm || Tscore_Bucket_Prior_Ntm || Risk_Segment_During_Rx || Tscore_Bucket_During_Rx || Change_T_Score || Change_Risk_Segment || Injectable_Experience_During_Rx || Comorb_Encounter_For_Screening_For_Malignant_Neoplasms || Comorb_Encounter_For_Immunization || Comorb_Encntr_For_General_Exam_W_O_Complaint,_Susp_Or_Reprtd_Dx || Comorb_Vitamin_D_Deficiency || Comorb_Other_Joint_Disorder_Not_Elsewhere_Classified || Comorb_Encntr_For_Oth_Sp_Exam_W_O_Complaint_Suspected_Or_Reprtd_Dx || Comorb_Long_Term_Current_Drug_Therapy || Comorb_Dorsalgia || Comorb_Personal_History_Of_Other_Diseases_And_Conditions || Comorb_Other_Disorders_Of_Bone_Density_And_Structure || Comorb_Disorders_of_lipoprotein_metabolism_and_other_lipidemias || Comorb_Osteoporosis_without_current_pathological_fracture || Comorb_Personal_history_of_malignant_neoplasm || Comorb_Gastro_esophageal_reflux_disease || Concom_Cholesterol_And_Triglyceride_Regulating_Preparations || Concom_Narcotics || Concom_Systemic_Corticosteroids_Plain || Concom_Anti_Depressants_And_Mood_Stabilisers || Concom_Fluoroquinolones || Concom_Cephalosporins || Concom_Macrolides_And_Similar_Types || Concom_Broad_Spectrum_Penicillins || Concom_Anaesthetics_General || Concom_Viral_Vaccines || Risk_Type_1_Insulin_Dependent_Diabetes || Risk_Osteogenesis_Imperfecta || Risk_Rheumatoid_Arthritis || Risk_Untreated_Chronic_Hyperthyroidism || Risk_Untreated_Chronic_Hypogonadism || Risk_Untreated_Early_Menopause || Risk_Patient_Parent_Fractured_Their_Hip || Risk_Smoking_Tobacco || Risk_Chronic_Malnutrition_Or_Malabsorption || Risk_Chronic_Liver_Disease || Risk_Family_History_Of_Osteoporosis || Risk_Low_Calcium_Intake || Risk_Vitamin_D_Insufficiency || Risk_Poor_Health_Frailty || Risk_Excessive_Thinness || Risk_Hysterectomy_Oophorectomy || Risk_Estrogen_Deficiency || Risk_Immobilization || Risk_Recurring_Falls || Count_Of_Risks\n",
      "\u001b[1m\u001b[34m\n",
      "Column Names (After Formatting):\u001b[0m \n",
      "ptid || persistency_flag || gender || race || ethnicity || region || age || speciality || gluco_prior_ntm || gluco_during_rx || dexa_freq_during_rx || dexa_during_rx || frag_frac_prior_ntm || frag_frac_during_rx || risk_segment_prior_ntm || tscore_bucket_prior_ntm || risk_segment_during_rx || tscore_bucket_during_rx || change_t_score || change_risk_segment || injectable_experience_during_rx || comorb_encounter_for_screening_for_malignant_neoplasms || comorb_encounter_for_immunization || comorb_encntr_for_general_exam_w_o_complaint_susp_or_reprtd_dx || comorb_vitamin_d_deficiency || comorb_other_joint_disorder_not_elsewhere_classified || comorb_encntr_for_oth_sp_exam_w_o_complaint_suspected_or_reprtd_dx || comorb_long_term_current_drug_therapy || comorb_dorsalgia || comorb_personal_history_of_other_diseases_and_conditions || comorb_other_disorders_of_bone_density_and_structure || comorb_disorders_of_lipoprotein_metabolism_and_other_lipidemias || comorb_osteoporosis_without_current_pathological_fracture || comorb_personal_history_of_malignant_neoplasm || comorb_gastro_esophageal_reflux_disease || concom_cholesterol_and_triglyceride_regulating_preparations || concom_narcotics || concom_systemic_corticosteroids_plain || concom_anti_depressants_and_mood_stabilisers || concom_fluoroquinolones || concom_cephalosporins || concom_macrolides_and_similar_types || concom_broad_spectrum_penicillins || concom_anaesthetics_general || concom_viral_vaccines || risk_type_1_insulin_dependent_diabetes || risk_osteogenesis_imperfecta || risk_rheumatoid_arthritis || risk_untreated_chronic_hyperthyroidism || risk_untreated_chronic_hypogonadism || risk_untreated_early_menopause || risk_patient_parent_fractured_their_hip || risk_smoking_tobacco || risk_chronic_malnutrition_or_malabsorption || risk_chronic_liver_disease || risk_family_history_of_osteoporosis || risk_low_calcium_intake || risk_vitamin_d_insufficiency || risk_poor_health_frailty || risk_excessive_thinness || risk_hysterectomy_oophorectomy || risk_estrogen_deficiency || risk_immobilization || risk_recurring_falls || count_of_risks\n"
     ]
    }
   ],
   "source": [
    "original_cols = data.columns\n",
    "cols_vis = ' || '.join(original_cols)\n",
    "print(colored(\"\\nColumn Names (Before Formatting):\", 'magenta', attrs = ['bold']),\"\\n{}\".format(cols_vis))\n",
    "\n",
    "#List of special characters that should not be present\n",
    "special_chars = r'[?|$|#|@|%|*|(|)|<|>|:|\"|{|}|,|.|;|!|^|\\|]'\n",
    "\n",
    "#Lower case and remove white spaces\n",
    "data.columns = list(map(lambda x:re.sub(special_chars,r'',x.lower().replace(' ','_').replace(\"'\",\"\").replace(\"|\",\"_\")), data.columns))\n",
    "\n",
    "updated_cols = data.columns\n",
    "cols_vis = ' || '.join(updated_cols)\n",
    "print(colored(\"\\nColumn Names (After Formatting):\", 'blue', attrs = ['bold']), \"\\n{}\".format(cols_vis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " <span style=\"color:darkgreen; font-style:italic; font-size:15px\">  <b>Data type of the loaded dataset is shown below   </b></span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ptid                              object\n",
       "persistency_flag                  object\n",
       "gender                            object\n",
       "race                              object\n",
       "ethnicity                         object\n",
       "                                   ...  \n",
       "risk_hysterectomy_oophorectomy    object\n",
       "risk_estrogen_deficiency          object\n",
       "risk_immobilization               object\n",
       "risk_recurring_falls              object\n",
       "count_of_risks                     int64\n",
       "Length: 65, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[35mNumerical columns:\n",
      "Count:\u001b[0m 2\n",
      "dexa_freq_during_rx || count_of_risks\n",
      "\u001b[1m\u001b[35mCategorical columns:\n",
      "Count:\u001b[0m 63\n",
      "risk_excessive_thinness || risk_vitamin_d_insufficiency || comorb_vitamin_d_deficiency || concom_cholesterol_and_triglyceride_regulating_preparations || tscore_bucket_prior_ntm || risk_untreated_early_menopause || injectable_experience_during_rx || risk_smoking_tobacco || risk_patient_parent_fractured_their_hip || frag_frac_prior_ntm || comorb_encounter_for_screening_for_malignant_neoplasms || speciality || region || ethnicity || comorb_disorders_of_lipoprotein_metabolism_and_other_lipidemias || concom_narcotics || gluco_prior_ntm || race || comorb_long_term_current_drug_therapy || comorb_personal_history_of_other_diseases_and_conditions || comorb_gastro_esophageal_reflux_disease || persistency_flag || concom_cephalosporins || concom_viral_vaccines || comorb_osteoporosis_without_current_pathological_fracture || concom_fluoroquinolones || concom_anaesthetics_general || dexa_during_rx || risk_hysterectomy_oophorectomy || concom_anti_depressants_and_mood_stabilisers || change_t_score || risk_rheumatoid_arthritis || gluco_during_rx || risk_poor_health_frailty || change_risk_segment || risk_family_history_of_osteoporosis || risk_type_1_insulin_dependent_diabetes || risk_osteogenesis_imperfecta || gender || comorb_encntr_for_oth_sp_exam_w_o_complaint_suspected_or_reprtd_dx || age || risk_estrogen_deficiency || comorb_encounter_for_immunization || risk_chronic_liver_disease || comorb_other_disorders_of_bone_density_and_structure || risk_low_calcium_intake || tscore_bucket_during_rx || comorb_dorsalgia || concom_broad_spectrum_penicillins || risk_untreated_chronic_hypogonadism || comorb_personal_history_of_malignant_neoplasm || concom_systemic_corticosteroids_plain || risk_chronic_malnutrition_or_malabsorption || comorb_encntr_for_general_exam_w_o_complaint_susp_or_reprtd_dx || risk_immobilization || concom_macrolides_and_similar_types || ptid || risk_segment_prior_ntm || risk_recurring_falls || frag_frac_during_rx || risk_untreated_chronic_hyperthyroidism || risk_segment_during_rx || comorb_other_joint_disorder_not_elsewhere_classified\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"\"\" <span style=\"color:darkgreen; font-style:italic; font-size:15px\">  <b>Data type of the loaded dataset is shown below   </b></span>\"\"\"))\n",
    "display(data.dtypes)\n",
    "\n",
    "cols = data.columns\n",
    "#Getting the list of numerical features\n",
    "num_cols = data._get_numeric_data().columns.tolist()\n",
    "num_cols_vis = ' || '.join(num_cols)\n",
    "print(colored(\"Numerical columns:\\nCount:\", 'magenta', attrs=['bold']),\"{}\\n{}\".format(len(num_cols),num_cols_vis))\n",
    "\n",
    "#Getting list of categorical features\n",
    "cat_cols = list(set(cols) - set(num_cols))\n",
    "cat_cols_vis = ' || '.join(cat_cols)\n",
    "print(colored(\"Categorical columns:\\nCount:\", 'magenta', attrs=['bold']),\"{}\\n{}\".format(len(cat_cols),cat_cols_vis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical columns summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Getting a summary of numerical columns where we see the averages and other representatives of numerical data to help us with feature pre-processing later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 columns   count    mean  median     std  min  \\\n",
      "dexa_freq_during_rx  dexa_freq_during_rx  3424.0  3.0161     0.0  8.1365  0.0   \n",
      "count_of_risks            count_of_risks  3424.0  1.2395     1.0  1.0949  0.0   \n",
      "\n",
      "                     IQR    max  skewness  kurtosis  \n",
      "dexa_freq_during_rx  3.0  146.0    6.8087   74.7584  \n",
      "count_of_risks       2.0    7.0    0.8798    0.9005  \n"
     ]
    }
   ],
   "source": [
    "if num_cols == []:\n",
    "    display(Markdown('__NO NUMERICAL COLUMNS AVAILABLE__'))\n",
    "else:\n",
    "    num_desc = data[num_cols].describe().T\n",
    "    num_desc.insert(loc=5,column='IQR',value = (num_desc['75%']-num_desc['25%']))\n",
    "    num_desc.drop(['25%','50%','75%'],axis=1,inplace=True)\n",
    "    \n",
    "    num_desc['skewness'] = data[num_cols].skew()\n",
    "    num_desc['kurtosis'] = data[num_cols].kurt()\n",
    "    num_desc.insert(loc=0, column='columns', value=num_desc.index)\n",
    "    num_desc.insert(loc=3, column = 'median', value=data[num_cols].median())\n",
    "    print(num_desc.round(4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical columns summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Getting a summary of categorical columns where we see the distribution across different labels of the categorical features to help us with feature pre-processing later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Category</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Percentage(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>risk_excessive_thinness</td>\n",
       "      <td>N</td>\n",
       "      <td>3357</td>\n",
       "      <td>98.0432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>risk_excessive_thinness</td>\n",
       "      <td>Y</td>\n",
       "      <td>67</td>\n",
       "      <td>1.9568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>risk_vitamin_d_insufficiency</td>\n",
       "      <td>N</td>\n",
       "      <td>1788</td>\n",
       "      <td>52.2196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>risk_vitamin_d_insufficiency</td>\n",
       "      <td>Y</td>\n",
       "      <td>1636</td>\n",
       "      <td>47.7804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comorb_vitamin_d_deficiency</td>\n",
       "      <td>N</td>\n",
       "      <td>2331</td>\n",
       "      <td>68.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3591</th>\n",
       "      <td>risk_segment_during_rx</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1497</td>\n",
       "      <td>43.7208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592</th>\n",
       "      <td>risk_segment_during_rx</td>\n",
       "      <td>HR_VHR</td>\n",
       "      <td>965</td>\n",
       "      <td>28.1834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3593</th>\n",
       "      <td>risk_segment_during_rx</td>\n",
       "      <td>VLR_LR</td>\n",
       "      <td>962</td>\n",
       "      <td>28.0958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3594</th>\n",
       "      <td>comorb_other_joint_disorder_not_elsewhere_clas...</td>\n",
       "      <td>N</td>\n",
       "      <td>2425</td>\n",
       "      <td>70.8236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3595</th>\n",
       "      <td>comorb_other_joint_disorder_not_elsewhere_clas...</td>\n",
       "      <td>Y</td>\n",
       "      <td>999</td>\n",
       "      <td>29.1764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3596 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Variable Category Frequency  \\\n",
       "0                               risk_excessive_thinness        N      3357   \n",
       "1                               risk_excessive_thinness        Y        67   \n",
       "2                          risk_vitamin_d_insufficiency        N      1788   \n",
       "3                          risk_vitamin_d_insufficiency        Y      1636   \n",
       "4                           comorb_vitamin_d_deficiency        N      2331   \n",
       "...                                                 ...      ...       ...   \n",
       "3591                             risk_segment_during_rx  Unknown      1497   \n",
       "3592                             risk_segment_during_rx   HR_VHR       965   \n",
       "3593                             risk_segment_during_rx   VLR_LR       962   \n",
       "3594  comorb_other_joint_disorder_not_elsewhere_clas...        N      2425   \n",
       "3595  comorb_other_joint_disorder_not_elsewhere_clas...        Y       999   \n",
       "\n",
       "      Percentage(%)  \n",
       "0           98.0432  \n",
       "1            1.9568  \n",
       "2           52.2196  \n",
       "3           47.7804  \n",
       "4           68.0783  \n",
       "...             ...  \n",
       "3591        43.7208  \n",
       "3592        28.1834  \n",
       "3593        28.0958  \n",
       "3594        70.8236  \n",
       "3595        29.1764  \n",
       "\n",
       "[3596 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cat_summ = pd.DataFrame(columns=['Variable','Category','Frequency','Percentage(%)'])\n",
    "for col in cat_cols:\n",
    "    cat_col_summary = pd.DataFrame(data[col].value_counts(dropna=False)).reset_index()\n",
    "    cat_col_summary.columns = ['Category','Frequency']\n",
    "    cat_col_summary['Percentage(%)'] = (cat_col_summary[\"Frequency\"]/cat_col_summary[\"Frequency\"].sum())*100\n",
    "    cat_col_summary['Variable'] = col\n",
    "    cat_summ = pd.concat([cat_summ, cat_col_summary],ignore_index = True)\n",
    "display(cat_summ[['Variable','Category','Frequency','Percentage(%)']].round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Category</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Percentage(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>&gt;75</td>\n",
       "      <td>1422</td>\n",
       "      <td>41.530374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>change_risk_segment</td>\n",
       "      <td>Worsened</td>\n",
       "      <td>2229</td>\n",
       "      <td>65.099299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>change_t_score</td>\n",
       "      <td>Worsened</td>\n",
       "      <td>1660</td>\n",
       "      <td>48.481308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>comorb_disorders_of_lipoprotein_metabolism_and...</td>\n",
       "      <td>Y</td>\n",
       "      <td>1765</td>\n",
       "      <td>51.547897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comorb_dorsalgia</td>\n",
       "      <td>Y</td>\n",
       "      <td>2645</td>\n",
       "      <td>77.248832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Variable  Category Frequency  \\\n",
       "0                                                age       >75      1422   \n",
       "1                                change_risk_segment  Worsened      2229   \n",
       "2                                     change_t_score  Worsened      1660   \n",
       "3  comorb_disorders_of_lipoprotein_metabolism_and...         Y      1765   \n",
       "4                                   comorb_dorsalgia         Y      2645   \n",
       "\n",
       "   Percentage(%)  \n",
       "0      41.530374  \n",
       "1      65.099299  \n",
       "2      48.481308  \n",
       "3      51.547897  \n",
       "4      77.248832  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_cat = cat_summ.groupby('Variable').aggregate('max').reset_index()\n",
    "max_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cat = cat_summ.groupby('Variable').aggregate('min').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Percentage(%)_x</th>\n",
       "      <th>Category_y</th>\n",
       "      <th>Percentage(%)_y</th>\n",
       "      <th>max_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>41.530374</td>\n",
       "      <td>55-65</td>\n",
       "      <td>4.760514</td>\n",
       "      <td>36.769860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>change_risk_segment</td>\n",
       "      <td>65.099299</td>\n",
       "      <td>Improved</td>\n",
       "      <td>0.642523</td>\n",
       "      <td>64.456776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>change_t_score</td>\n",
       "      <td>48.481308</td>\n",
       "      <td>Improved</td>\n",
       "      <td>2.745327</td>\n",
       "      <td>45.735981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>comorb_disorders_of_lipoprotein_metabolism_and...</td>\n",
       "      <td>51.547897</td>\n",
       "      <td>N</td>\n",
       "      <td>48.452103</td>\n",
       "      <td>3.095794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comorb_dorsalgia</td>\n",
       "      <td>77.248832</td>\n",
       "      <td>N</td>\n",
       "      <td>22.751168</td>\n",
       "      <td>54.497664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Variable  Percentage(%)_x  \\\n",
       "0                                                age        41.530374   \n",
       "1                                change_risk_segment        65.099299   \n",
       "2                                     change_t_score        48.481308   \n",
       "3  comorb_disorders_of_lipoprotein_metabolism_and...        51.547897   \n",
       "4                                   comorb_dorsalgia        77.248832   \n",
       "\n",
       "  Category_y  Percentage(%)_y   max_diff  \n",
       "0      55-65         4.760514  36.769860  \n",
       "1   Improved         0.642523  64.456776  \n",
       "2   Improved         2.745327  45.735981  \n",
       "3          N        48.452103   3.095794  \n",
       "4          N        22.751168  54.497664  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max_cat = max_cat.merge(min_cat, on = 'Variable', how='left')\n",
    "min_max_cat.drop(['Category_x','Frequency_x','Frequency_y'], axis=1, inplace=True)\n",
    "min_max_cat['max_diff'] = (min_max_cat['Percentage(%)_x']-min_max_cat['Percentage(%)_y']).abs()\n",
    "min_max_cat.head()\n",
    "min_max_cat.drop(min_max_cat[min_max_cat.max_diff > 65].index, inplace=True)\n",
    "min_max_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_cols = min_max_cat.Variable.unique().tolist()\n",
    "# cat_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "__NO MISSING DATA __"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check missing values\n",
    "data.columns[data.isna().any()]\n",
    "display(Markdown('__NO MISSING DATA __'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "identifier = ['ptid']\n",
    "target = ['persistency_flag']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filtering for independent categorical coumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering for independent cat_cols\n",
    "\n",
    "ind_cat_cols = list(set(cat_cols) - set(identifier) - set(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding categorical features with two labels\n",
    "\n",
    "cat_cols_2_label = list(data.columns[data.nunique()==2])\n",
    "ind_cat_cols_2_label = list(set(ind_cat_cols).intersection(set(cat_cols_2_label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Categorical data cannot be passed directly through a classifier (although a decision tree based classifier can still give an estimate but better to encode and change them into numerical features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### As a rule of thumb, using one hot encoding for categorical variables with 2 labels and label encoding for rest of the categorical features with more than 2 labels (to avoid the curse of dimensionality)\n",
    "##### One hot encoding also comes with a possibility of dummy data curse, since a label False is nothing but Not True and hence says the same information as the True flag. Keeping both in the data will increase collinearity. Hence such cases are removed from the data hile performing one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ptid</th>\n",
       "      <th>gluco_during_rx_Y</th>\n",
       "      <th>risk_poor_health_frailty_Y</th>\n",
       "      <th>risk_excessive_thinness_Y</th>\n",
       "      <th>risk_family_history_of_osteoporosis_Y</th>\n",
       "      <th>risk_vitamin_d_insufficiency_Y</th>\n",
       "      <th>comorb_vitamin_d_deficiency_Y</th>\n",
       "      <th>risk_type_1_insulin_dependent_diabetes_Y</th>\n",
       "      <th>risk_osteogenesis_imperfecta_Y</th>\n",
       "      <th>concom_cholesterol_and_triglyceride_regulating_preparations_Y</th>\n",
       "      <th>...</th>\n",
       "      <th>concom_anaesthetics_general_Y</th>\n",
       "      <th>risk_segment_prior_ntm_VLR_LR</th>\n",
       "      <th>risk_recurring_falls_Y</th>\n",
       "      <th>dexa_during_rx_Y</th>\n",
       "      <th>frag_frac_during_rx_Y</th>\n",
       "      <th>risk_hysterectomy_oophorectomy_Y</th>\n",
       "      <th>concom_anti_depressants_and_mood_stabilisers_Y</th>\n",
       "      <th>risk_untreated_chronic_hyperthyroidism_Y</th>\n",
       "      <th>risk_rheumatoid_arthritis_Y</th>\n",
       "      <th>comorb_other_joint_disorder_not_elsewhere_classified_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P701</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P702</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P703</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P704</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P705</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ptid  gluco_during_rx_Y  risk_poor_health_frailty_Y  \\\n",
       "0  P701                  0                           0   \n",
       "1  P702                  0                           0   \n",
       "2  P703                  0                           0   \n",
       "3  P704                  1                           0   \n",
       "4  P705                  1                           0   \n",
       "\n",
       "   risk_excessive_thinness_Y  risk_family_history_of_osteoporosis_Y  \\\n",
       "0                          0                                      0   \n",
       "1                          0                                      0   \n",
       "2                          0                                      0   \n",
       "3                          0                                      0   \n",
       "4                          0                                      0   \n",
       "\n",
       "   risk_vitamin_d_insufficiency_Y  comorb_vitamin_d_deficiency_Y  \\\n",
       "0                               0                              0   \n",
       "1                               0                              0   \n",
       "2                               0                              0   \n",
       "3                               0                              0   \n",
       "4                               0                              0   \n",
       "\n",
       "   risk_type_1_insulin_dependent_diabetes_Y  risk_osteogenesis_imperfecta_Y  \\\n",
       "0                                         0                               0   \n",
       "1                                         0                               0   \n",
       "2                                         0                               0   \n",
       "3                                         0                               0   \n",
       "4                                         0                               0   \n",
       "\n",
       "   concom_cholesterol_and_triglyceride_regulating_preparations_Y  ...  \\\n",
       "0                                                  0              ...   \n",
       "1                                                  0              ...   \n",
       "2                                                  1              ...   \n",
       "3                                                  0              ...   \n",
       "4                                                  0              ...   \n",
       "\n",
       "   concom_anaesthetics_general_Y  risk_segment_prior_ntm_VLR_LR  \\\n",
       "0                              0                              1   \n",
       "1                              0                              1   \n",
       "2                              0                              0   \n",
       "3                              0                              0   \n",
       "4                              0                              0   \n",
       "\n",
       "   risk_recurring_falls_Y  dexa_during_rx_Y  frag_frac_during_rx_Y  \\\n",
       "0                       0                 0                      0   \n",
       "1                       0                 0                      0   \n",
       "2                       0                 0                      0   \n",
       "3                       0                 0                      0   \n",
       "4                       0                 0                      0   \n",
       "\n",
       "   risk_hysterectomy_oophorectomy_Y  \\\n",
       "0                                 0   \n",
       "1                                 0   \n",
       "2                                 0   \n",
       "3                                 0   \n",
       "4                                 0   \n",
       "\n",
       "   concom_anti_depressants_and_mood_stabilisers_Y  \\\n",
       "0                                               0   \n",
       "1                                               0   \n",
       "2                                               0   \n",
       "3                                               0   \n",
       "4                                               1   \n",
       "\n",
       "   risk_untreated_chronic_hyperthyroidism_Y  risk_rheumatoid_arthritis_Y  \\\n",
       "0                                         0                            0   \n",
       "1                                         0                            0   \n",
       "2                                         0                            0   \n",
       "3                                         0                            0   \n",
       "4                                         0                            0   \n",
       "\n",
       "   comorb_other_joint_disorder_not_elsewhere_classified_Y  \n",
       "0                                                  0       \n",
       "1                                                  0       \n",
       "2                                                  0       \n",
       "3                                                  1       \n",
       "4                                                  0       \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filt = ind_cat_cols_2_label+identifier\n",
    "dummy_data_2_label = pd.get_dummies(data[filt], columns = ind_cat_cols_2_label, drop_first=True, dtype = np.int64)\n",
    "dummy_data_2_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['change_risk_segment', 'age', 'race', 'speciality', 'region', 'ethnicity', 'change_t_score', 'risk_segment_during_rx', 'tscore_bucket_during_rx']\n"
     ]
    }
   ],
   "source": [
    "ind_cat_cols_n_label = list(set(ind_cat_cols)-set(ind_cat_cols_2_label))\n",
    "\n",
    "print(ind_cat_cols_n_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le_data = pd.DataFrame()\n",
    "for i in ind_cat_cols_n_label:\n",
    "    le_data[i] = le.fit_transform(data[i])\n",
    "le_data['ptid'] = data['ptid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3424, 65)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Final encoded data (Excluding target variable)\n",
    "\n",
    "data_enc = pd.DataFrame()\n",
    "keep = ['ptid']+num_cols\n",
    "data_enc = data[keep]\n",
    "data_enc['persistency_flag'] = np.where(data['persistency_flag'] == 'Persistent', 1, data['persistency_flag'])\n",
    "data_enc['persistency_flag'] = np.where(data_enc['persistency_flag'] == 'Non-Persistent', 0, data_enc['persistency_flag'])\n",
    "data_enc = data_enc.merge(dummy_data_2_label, how='left').merge(le_data, how='left')\n",
    "data_enc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Validation-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validation set is usuaaly the set on the basis of which multiple iterations are run in order to get at the best model/parameters. Test set is the set on which final performance measyrement is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      "Train-validation-test split has been performed\n",
      "\u001b[0m\n",
      "\u001b[1m\u001b[35m\n",
      "Training-Validation/test split percentage:\u001b[0m \u001b[1m\u001b[34m\t70:30 (%)\u001b[0m\n",
      "\u001b[1m\u001b[35m\n",
      "Total Observations:\u001b[0m \u001b[1m\u001b[34m\t3424 \u001b[0m\n",
      "\u001b[1m\u001b[35m\n",
      "Total Independent Features:\u001b[0m \u001b[1m\u001b[34m\t64 \u001b[0m\n",
      "\u001b[1m\u001b[35m\\Training Observations:\u001b[0m \u001b[1m\u001b[34m\t2396 \u001b[0m\n",
      "\u001b[1m\u001b[35m\\Validation Observations:\u001b[0m \u001b[1m\u001b[34m\t514 \u001b[0m\n",
      "\u001b[1m\u001b[35m\n",
      "Test Observations:\u001b[0m \u001b[1m\u001b[34m\t514 \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Train-Validation-test split\n",
    "ind = list(set(list(data_enc.columns)) - set(target))\n",
    "split_perc = 0.30\n",
    "X = data_enc[ind]\n",
    "Y = data_enc[target]\n",
    "\n",
    "X_train, X_test_val, Y_train, Y_test_val = train_test_split(X,Y, test_size = split_perc, random_state = 41)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_test_val,Y_test_val, test_size = 0.50, random_state = 41)\n",
    "\n",
    "print(colored(\"\\nTrain-validation-test split has been performed\\n\", 'green', attrs = ['bold']))\n",
    "print(colored(\"\\nTraining-Validation/test split percentage:\", 'magenta', attrs = ['bold']), colored(\"\\t{}:{} (%)\", 'blue', attrs = ['bold']).format(int((1-split_perc)*100), int(split_perc*100)))\n",
    "print(colored(\"\\nTotal Observations:\", 'magenta', attrs = ['bold']), colored(\"\\t{} \", 'blue', attrs=['bold']).format(X.shape[0]))\n",
    "print(colored(\"\\nTotal Independent Features:\", 'magenta', attrs = ['bold']), colored(\"\\t{} \", 'blue', attrs=['bold']).format(X.shape[1]))\n",
    "print(colored(\"\\Training Observations:\", 'magenta', attrs = ['bold']), colored(\"\\t{} \", 'blue', attrs=['bold']).format(X_train.shape[0]))\n",
    "print(colored(\"\\Validation Observations:\", 'magenta', attrs = ['bold']), colored(\"\\t{} \", 'blue', attrs=['bold']).format(X_val.shape[0]))\n",
    "print(colored(\"\\nTest Observations:\", 'magenta', attrs = ['bold']), colored(\"\\t{} \", 'blue', attrs=['bold']).format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing linear dependency between independent variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Variance inflation factor is used to capture the linear dependency of independent factors on each other. A high VIF value implies the feature has dependency with more features/higher dependency with some features. The calculation is insipired by R-square value post regression line fit and hence the formula for VIF = 1/(1-R**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear dependency through VIF\n",
    "\n",
    "X_train_processed = copy.deepcopy(X_train)\n",
    "X_train_VIF = X_train_processed.drop(\"ptid\", axis=1, inplace=False)\n",
    "exog_df = add_constant(X_train_VIF)\n",
    "vifs = pd.Series([1/(1. - OLS(exog_df[col].values,\n",
    "                              exog_df.loc[:, exog_df.columns!=col].values).fit().rsquared) for col in exog_df],\n",
    "                 index = exog_df.columns,\n",
    "                 name = 'VIF')\n",
    "vifs = pd.DataFrame(vifs)\n",
    "vifs.drop('const', axis = 0, inplace = True)\n",
    "vifs = vifs['VIF'].where(vifs['VIF'] <= 15, 15)\n",
    "vifs = pd.DataFrame(vifs)\n",
    "vifs = vifs.sort_values(by=['VIF'],ascending = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dropping the collinear features from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "multicorr_vars = vifs['VIF'].loc[lambda X: X>=10].index.tolist()\n",
    "multicorr_vars.remove('count_of_risks')\n",
    "X_train_VIF.drop(multicorr_vars, axis =1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variability check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### COnstant/Quasi-constant variables OR variables with close to 0 standard deviation usually do not show enough variation to give any useful insights into the effect on the response variable. Hence its preferred to have more standard deviation for features, upto an extent, provided no normalization of the data has been perfoemed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variability_check(df):\n",
    "    df_desc = df.describe().loc['std'] == 0\n",
    "    return df_desc[df_desc].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features =[]\n",
    "selected_features_dict = {}\n",
    "col_drop = []\n",
    "\n",
    "zero_variance = variability_check(X_train_VIF)\n",
    "if len(zero_variance) == 0:\n",
    "    print(colored(\"\\nNo quasi-constant features/no column with 0 std dev\", \"green\", attrs = ['bold']))\n",
    "else:\n",
    "    display(Markdown('<span style = \"color:darkred\"><br><b>QUASI_CONSTANT FEATURES'))\n",
    "    display(pd.DataFrame(zero_variance, columns = [\"Features\"]))\n",
    "print(colored(\"Standard Deviation of the data:\", 'magenta', attrs = ['bold']))\n",
    "display(pd.DataFrame(X_train_VIF.describe().loc['std'].round(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Balancing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imbalanced dataset ill bias the training of the model towards the class with hugher value count in the dataset. To avoid this, the dataset is first balanced with respect to the response variable and then training is run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_summ[cat_summ.Variable == 'persistency_flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Over or Under sampling are two of the options for balancing a dataset. Here oversampling has been used for the following reasons - \n",
    "##### 1. Less data availability\n",
    "##### 2. Less variation in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Oversampling\n",
    "\n",
    "label = \"SMOTE\"\n",
    "smotesampler = SMOTE(random_state = 41)\n",
    "X_train_bal, Y_train_bal= smotesampler.fit_resample(X_train_VIF, Y_train.astype('boolean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_count = 10\n",
    "selected_model_feat = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance/Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inclination towards tree based classifiers provided the dataset being categorically heavy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train_bal\n",
    "Y = Y_train_bal\n",
    "\n",
    "xg = XGBClassifier()\n",
    "xg_model = xg.fit(X,Y)\n",
    "xg_coeff = pd.DataFrame(np.round(xg_model.feature_importances_,4)).abs()\n",
    "df_xgb = pd.concat([pd.DataFrame(X.columns), xg_coeff], axis=1)\n",
    "df_xgb.columns = ['Features','Importance']\n",
    "df_xgb = df_xgb.sort_values(by = 'Importance', ascending = False).reset_index(drop=True)\n",
    "display(df_xgb[['Features','Importance']].head(15).round(4))\n",
    "\n",
    "selected_model_feat.update({\"XGB\": df_xgb.Features.tolist()[:feature_count]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rf = X_train_bal\n",
    "Y_rf = Y_train_bal\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf_model = rf.fit(X_rf,Y_rf)\n",
    "rf_coeff = pd.DataFrame(np.round(rf_model.feature_importances_,4)).abs()\n",
    "df_rf = pd.concat([pd.DataFrame(X.columns), rf_coeff], axis=1)\n",
    "df_rf.columns = ['Features','Importance']\n",
    "df_rf = df_rf.sort_values(by = 'Importance', ascending = False).reset_index(drop=True)\n",
    "display(df_rf[['Features','Importance']].head(15).round(4))\n",
    "\n",
    "selected_model_feat.update({\"RF\": df_rf.Features.tolist()[:feature_count]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final feature list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_feat = list(set(selected_model_feat['XGB']) | set(selected_model_feat['RF']))\n",
    "len(final_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(colored(\"\\nFinal feature list:\", 'magenta', attrs = ['bold']), ' || '.join(final_feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_final = [\"gluco_record_prior_ntm\",\"frag_frac_prior_ntm\",\"dexa_during_rx\",\"concom_viral_vaccines\", \"risk_segment_during_rx\",\n",
    "\"ntm_speciality\",\"age_bucket\",\"concom_systemic_corticosteroids_plain\",\n",
    "\"comorb_encntr_for_general_exam_w_o_complaint_susp_or_reprtd_dx\",\"dexa_freq_during_rx\",\n",
    "\"comorb_encounter_for_immunization\",\"comorb_encounter_for_screening_for_malignant_neoplasms\",\n",
    "\"region\",\"tscore_bucket_during_rx\",\"concom_viral_vaccines\",\"comorb_long_term_current_drug_therapy\",\"change_risk_segment\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Post getting the list of final featres which seem to be important provided the response variable, we can manually plot and check potential patterns of each of the independent feature with the response variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "m=1\n",
    "for i in feature_final:\n",
    "    plt.figure(m+1)\n",
    "    m+=1\n",
    "    sns.histplot(binwidth=0.5, x=i, hue=\"persistency_flag\", data=data, stat=\"percent\", multiple=\"dodge\", legend = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UDFs to make iterative function calls easier and reusability possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_function(model_name, x_train, y_train):\n",
    "    if model_name == 'XGB':\n",
    "        params = {'learning_rate':[0.15,0.10,0.05],\n",
    "                  'max_depth':[2,3,4,5],\n",
    "                  'gamma':[0.0,0.1,0.2,0.3]}\n",
    "        classifier = XGBClassifier()\n",
    "        random_search = RandomizedSearchCV(classifier, param_distributions = params, cv=3, n_iter = 5, scoring = 'roc_auc', verbose = 3)\n",
    "        \n",
    "        model_opt = random_search.fit(x_train, y_train)\n",
    "        opt_params = model_opt.best_params_\n",
    "        classifier = classifier.set_params(**opt_params)\n",
    "        model = classifier.fit(x_train, y_train)\n",
    "        y_prob_train = model.predict_proba(x_train)\n",
    "        cv = cross_val_score(classifier, x_train, y_train, cv=3, scoring = 'f1_macro')\n",
    "    if model_name == 'RF':\n",
    "        params = {'n_estimators':[100,200,300],\n",
    "                  'max_depth':[2,3,4,5],\n",
    "                  'min_samples_split':[3,4,5,6,7],\n",
    "                  'min_samples_leaf':[1,2,3]}\n",
    "        classifier = RandomForestClassifier()\n",
    "        random_search = RandomizedSearchCV(classifier, param_distributions = params, cv=3, n_iter = 5, scoring = 'roc_auc', verbose = 3)\n",
    "        \n",
    "        model_opt = random_search.fit(x_train, y_train)\n",
    "        opt_params = model_opt.best_params_\n",
    "        classifier = classifier.set_params(**opt_params)\n",
    "        model = classifier.fit(x_train, y_train)\n",
    "        y_prob_train = model.predict_proba(x_train)\n",
    "        cv = cross_val_score(classifier, x_train, y_train, cv=3, scoring = 'f1_macro')\n",
    "    return model, y_prob_train, cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Opt_thres(target, predicted, p, r, threshold_roc):\n",
    "    n = min(len(threshold_roc), len(p))\n",
    "    p=p[0:n]\n",
    "    r=r[0:n]\n",
    "    threshold_roc = threshold_roc[0:n]\n",
    "    i = np.arange(len(1-r))\n",
    "    roc = pd.DataFrame({'tf':pd.Series(p-r, index=i), 'threshold' : pd.Series(threshold_roc, index=i)})\n",
    "    roc_t = roc.iloc[(roc.tf-0).abs().argsort()[:-1]]\n",
    "\n",
    "    return list(roc_t['threshold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_summary(y_train, y_prob, pos_class):\n",
    "    fpr, tpr, threshold_roc = metrics.roc_curve(y_train,y_prob,pos_label = pos_class)\n",
    "    threshold_roc[0]=1\n",
    "    roc_auc = metrics.auc(fpr,tpr)\n",
    "    p,r,thresholds = precision_recall_curve(y_train,y_prob,pos_label = pos_class)\n",
    "    optimal_threshold = OP(y_train, y_prob, tpr, (1-fpr), threshold_roc)[0]\n",
    "\n",
    "    return p,r,thresholds,optimal_threshold, fpr, tpr, roc_auc, threshold_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_plot(fpr, tpr):\n",
    "    if sum(tpr) > sum(fpr):\n",
    "        roc_auc = metrics.auc(fpr,tpr)\n",
    "    else:\n",
    "        roc_auc = metrics.auc(tpr,fpr)\n",
    "    roc_fig = go.Figure()\n",
    "    roc_fig.add_trace(go.Scatter(x=fpr,y=tpr,mode = 'lines', line = dict(color='navy',width=2, dash = 'dash')))\n",
    "    roc_fig.add_trace(go.Scatter(name = 'AUC - %0.2f' % roc_auc, y=tpr, x=fpr, fill = 'tonexty', mode = 'lines', line_color = 'magenta'))\n",
    "    roc_fig.update_layout(title = {'text':'ROC', 'y':0.9, 'x':0.5}, width = 900, height = 700)\n",
    "    roc.update_xaxes(title = '1-Specificity')\n",
    "    roc.update_yaxes(title = 'Sensitivity')\n",
    "    roc_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the best model on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'XGB'\n",
    "model, y_proba_train, cvs = fit_function(model_name, X_train_bal[final_feat], Y_train_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p,r,thresholds, optimal_threshold, fpr, tpr, roc_auc, threshold_roc = classification_summary(Y_train_bal, y_proba_train[:,0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### More the are under the curve, better the model performance. Since we have less data coverage and even distribution, the model tries its best to capture the available patterns present in the data and so is the inclination towards low accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr,tpr)\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGB Final Results\n",
    "\n",
    "Y_pred_train = np.where(y_proba_train[:,0] > optimal_threshold, True, False)\n",
    "optimal_threshold\n",
    "cm_xgb = confusion_matrix(Y_train_bal, Y_pred_train, labels = [True,False])\n",
    "tn,fp,fn,tp = confusion_matrix(Y_train_bal, Y_pred_train, labels = [True,False]).ravel()\n",
    "\n",
    "accuracy_xgb = round(accuracy_score(y_pred = Y_pred_train, y_true = Y_train_bal),2)\n",
    "precision_xgb = round(precision_score(y_pred = Y_pred_train, y_true = Y_train_bal, pos_label = True),2)\n",
    "recall_xgb = round(recall_score(y_pred = Y_pred_train, y_true = Y_train_bal, pos_label = True),2)\n",
    "f1_score_xgb = round(2*precision_xgb*recall_xgb/(precision_xgb+recall_xgb),2)\n",
    "specificity_xgb = round(tn/(tn+fp),2)\n",
    "\n",
    "auc = metrics.roc_auc_score(Y_train_bal, Y_pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"\"\" <span style=\"color:darkgreen; font-style:italic; font-size:15px\">  <b> Final Results of XGBoost Classifier   </b></span>\"\"\"))\n",
    "\n",
    "print(colored(\"\\nOptimal Threshold:\",'magenta', attrs=['bold']),round(optimal_threshold,2))\n",
    "print(colored(\"\\nConfusion matrix:\",'magenta', attrs=['bold']),cm_xgb)\n",
    "print(colored(\"\\nAccuracy:\",'magenta', attrs=['bold']),accuracy_xgb)\n",
    "print(colored(\"\\Precision:\",'magenta', attrs=['bold']),precision_xgb)\n",
    "print(colored(\"\\Recall:\",'magenta', attrs=['bold']),recall_xgb)\n",
    "print(colored(\"\\nF1 Score:\",'magenta', attrs=['bold']),f1_score_xgb)\n",
    "print(colored(\"\\nArea Under The Curve:\",'magenta', attrs=['bold']),round(auc,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying Undersampling with RF as previous model accuracy was low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Undersampling\n",
    "\n",
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "label = \"US - NM\"\n",
    "NMundersample = NearMiss(version=1, n_neighbors=3)\n",
    "X_train_bal_RF, Y_train_bal_RF= NMundersample.fit_resample(X_train_VIF, Y_train.astype('boolean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_RF = X_train_bal_RF\n",
    "Y_RF = Y_train_bal_RF\n",
    "\n",
    "RF = RandomForestClassifier()\n",
    "RF_model = rf.fit(X_RF,Y_RF)\n",
    "RF_coeff = pd.DataFrame(np.round(RF_model.feature_importances_,4)).abs()\n",
    "df_RF = pd.concat([pd.DataFrame(X.columns), RF_coeff], axis=1)\n",
    "df_RF.columns = ['Features','Importance']\n",
    "df_RF = df_RF.sort_values(by = 'Importance', ascending = False).reset_index(drop=True)\n",
    "display(df_RF[['Features','Importance']].head(10).round(4))\n",
    "\n",
    "final_features_RF = df_RF.Features.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bal_RF = X_train_bal_RF[final_features_RF]\n",
    "\n",
    "model_name = 'XGB'\n",
    "model_RF, y_proba_train_RF, cvs_RF = fit_function(model_name, X_train_bal_RF, Y_train_bal_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_RF,r_RF,thresholds_RF, optimal_threshold_RF, fpr_RF, tpr_RF, roc_auc_RF, threshold_roc_RF = classification_summary(Y_train_bal_RF, y_proba_train_RF[:,0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr_RF,tpr_RF)\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RF Final Results\n",
    "\n",
    "Y_pred_train_RF = np.where(y_proba_train_RF[:,0] > optimal_threshold_RF, True, False)\n",
    "print(optimal_threshold_RF)\n",
    "cm_RF = confusion_matrix(Y_train_bal_RF, Y_pred_train_RF, labels = [True,False])\n",
    "tn_RF,fp_RF,fn_RF,tp_RF = confusion_matrix(Y_train_bal_RF, Y_pred_train_RF, labels = [True,False]).ravel()\n",
    "print(tn_RF,fp_RF,fn_RF,tp_RF)\n",
    "\n",
    "accuracy_RF = round(accuracy_score(y_pred = Y_pred_train_RF, y_true = Y_train_bal_RF),2)\n",
    "precision_RF = round(precision_score(y_pred = Y_pred_train_RF, y_true = Y_train_bal_RF, pos_label = True),2)\n",
    "recall_RF = round(recall_score(y_pred = Y_pred_train_RF, y_true = Y_train_bal_RF, pos_label = True),2)\n",
    "f1_score_RF = round(2*precision_RF*recall_RF/(precision_RF+recall_RF),2)\n",
    "specificity_RF = round(tn_RF/(tn_RF+fp_RF),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"\"\" <span style=\"color:darkgreen; font-style:italic; font-size:15px\">  <b> Final Results of Random Forest Classifier   </b></span>\"\"\"))\n",
    "\n",
    "print(colored(\"\\nOptimal Threshold:\",'magenta', attrs=['bold']),round(optimal_threshold_RF,2))\n",
    "print(colored(\"\\nConfusion matrix:\",'magenta', attrs=['bold']),cm_RF)\n",
    "print(colored(\"\\nAccuracy:\",'magenta', attrs=['bold']),accuracy_RF)\n",
    "print(colored(\"\\Precision:\",'magenta', attrs=['bold']),precision_RF)\n",
    "print(colored(\"\\Recall:\",'magenta', attrs=['bold']),recall_RF)\n",
    "print(colored(\"\\nF1 Score:\",'magenta', attrs=['bold']),f1_score_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going with XGBoost classifier provided its performance is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_value = pd.DataFrame(Y_pred_train)\n",
    "Y_pred_value.columns = ['predicted_persistency_flag']\n",
    "Y_pred_value.loc[Y_pred_value['predicted_persistency_flag'] == True, 'predicted_persistency_flag'] = 'Persistent'\n",
    "Y_pred_value.loc[Y_pred_value['predicted_persistency_flag'] == False, 'predicted_persistency_flag'] = 'Non-Persistent'\n",
    "Y_pred_value.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_bal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_value = pd.DataFrame(Y_train_bal)\n",
    "Y_train_value = Y_train_value.astype('int64')\n",
    "Y_train_value.columns = ['actual_persistency_flag']\n",
    "Y_train_value.loc[Y_train_value['actual_persistency_flag'] == True, 'actual_persistency_flag'] = 'Persistent'\n",
    "Y_train_value.loc[Y_train_value['actual_persistency_flag'] == False, 'actual_persistency_flag'] = 'Non-Persistent'\n",
    "Y_train_value.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_bal.concat(Y_train_bal, axis = 1).concat(predjaj, axis = 1).head()\n",
    "export_data = pd.concat([X_train_bal,Y_train_value, Y_pred_value], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_data.to_excel('Final_data.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
